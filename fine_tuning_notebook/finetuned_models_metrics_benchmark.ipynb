{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Prerequisite Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pretained models with HuggingFace's transformers Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, TextClassificationPipeline\n",
    "from transformers import TFBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at curse_detection/klue-bert-base were not used when initializing TFBertForSequenceClassification: ['dropout_113']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at curse_detection/klue-bert-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n",
      "Some layers from the model checkpoint at curse_detection/klue-roberta-base were not used when initializing TFBertForSequenceClassification: ['dropout_37']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at curse_detection/klue-roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# load finetuned models from local\n",
    "klue_bert_tokenizer = AutoTokenizer.from_pretrained('curse_detection/klue-bert-base', from_tf=True)\n",
    "klue_bert_model = TFBertForSequenceClassification.from_pretrained('curse_detection/klue-bert-base', output_attentions=True)\n",
    "kcelectra_tokenizer = AutoTokenizer.from_pretrained('curse_detection/kcelectra-base')\n",
    "kcelectra_model = AutoModelForSequenceClassification.from_pretrained('curse_detection/kcelectra-base', output_attentions=True)\n",
    "kcbert_tokenizer = AutoTokenizer.from_pretrained('curse_detection/kcbert-base')\n",
    "kcbert_model = AutoModelForSequenceClassification.from_pretrained('curse_detection/kcbert-base', output_attentions=True)\n",
    "klue_roberta_tokenizer = AutoTokenizer.from_pretrained('curse_detection/klue-roberta-base', from_tf=True)\n",
    "klue_roberta_model = TFBertForSequenceClassification.from_pretrained('curse_detection/klue-roberta-base', output_attentions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load finetuned models from hugging face\n",
    "klue_bert_tokenizer = AutoTokenizer.from_pretrained('Tolerblanc/klue-bert-finetuned', from_tf=True)\n",
    "klue_bert_model = AutoModelForSequenceClassification.from_pretrained('Tolerblanc/klue-bert-finetuned', output_attentions=True, from_tf=True)\n",
    "kcelectra_tokenizer = AutoTokenizer.from_pretrained('Tolerblanc/kcelectra-base')\n",
    "kcelectra_model = AutoModelForSequenceClassification.from_pretrained('Tolerblanc/kcelectra-base', output_attentions=True)\n",
    "kcbert_tokenizer = AutoTokenizer.from_pretrained('Tolerblanc/kcbert-base')\n",
    "kcbert_model = AutoModelForSequenceClassification.from_pretrained('Tolerblanc/kcbert-base', output_attentions=True)\n",
    "klue_roberta_tokenizer = AutoTokenizer.from_pretrained('Tolerblanc/klue-roberta-base', from_tf=True)\n",
    "klue_roberta_model = AutoModelForSequenceClassification.from_pretrained('Tolerblanc/klue-roberta-base', output_attentions=True, from_tf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.context._EagerDeviceContext at 0x2cdc329c0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensorflow, torch GPU Acceleration in M1 Mac\n",
    "import torch\n",
    "torch_device = torch.device('mps:0' if torch.backends.mps.is_available() else 'cpu')\n",
    "import tensorflow as tf\n",
    "tf.device('/GPU:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "klue_bert_classifier = TextClassificationPipeline(\n",
    "    tokenizer=klue_bert_tokenizer, \n",
    "    model=klue_bert_model, \n",
    "    framework='tf',\n",
    ")\n",
    "kcelectra_classifier = TextClassificationPipeline(\n",
    "    tokenizer=kcelectra_tokenizer, \n",
    "    model=kcelectra_model, \n",
    "    framework='pt',\n",
    "    device=torch_device\n",
    ")\n",
    "klue_roberta_classifier = TextClassificationPipeline(\n",
    "    tokenizer=klue_roberta_tokenizer, \n",
    "    model=klue_roberta_model, \n",
    "    framework='tf',\n",
    ")\n",
    "kcbert_classifier = TextClassificationPipeline(\n",
    "    tokenizer=kcbert_tokenizer, \n",
    "    model=kcbert_model, \n",
    "    framework='pt',\n",
    "    device=torch_device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대조군으로 사용할 모델\n",
    "# JminJ 님의 kcElectra 기반 파인튜닝 모델\n",
    "# 아웃풋 0이 bad, 1이 clean\n",
    "# https://github.com/JminJ/Bad_text_classifier\n",
    "comparison_tokenizer = AutoTokenizer.from_pretrained('JminJ/kcElectra_base_Bad_Sentence_Classifier')\n",
    "comparison_model = AutoModelForSequenceClassification.from_pretrained('JminJ/kcElectra_base_Bad_Sentence_Classifier')\n",
    "comparison_classifier = TextClassificationPipeline(\n",
    "    tokenizer=comparison_tokenizer, \n",
    "    model=comparison_model, \n",
    "    framework='pt',\n",
    "    device=torch_device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/2runo/Curse-detection-data.git benchmark_dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>좌배 까는건 ㅇㅂ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>집에 롱 패딩만 세 개다. 10년 더 입어야지 ㅋㅋ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>개소리야 니가 빨갱이를 옹호하고 드루킹을 ㅇㅇ짓이라고 말못해서 삐진거야 빨갱아</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>세탁이라고 봐도 된다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>애새끼가 초딩도 아니고 ㅋㅋㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5820</th>\n",
       "      <td>좌우 헬파이어 3개씩 6개 장착에 아파치보다 약하지만 20mm 기관포 장착임</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5821</th>\n",
       "      <td>세금 내놓으라고 데모질 중 ㅋㅋ간첩, 도둑놈 새끼들이 대통령 해처먹으니까  나도 같...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5822</th>\n",
       "      <td>너가 한 말 중에</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5823</th>\n",
       "      <td>제갈대중 ㅇㅂ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5824</th>\n",
       "      <td>우리나라교회는 악마들이모여 주뎅이 처벌리고</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5825 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               document  label\n",
       "0                                             좌배 까는건 ㅇㅂ      1\n",
       "1                          집에 롱 패딩만 세 개다. 10년 더 입어야지 ㅋㅋ      0\n",
       "2           개소리야 니가 빨갱이를 옹호하고 드루킹을 ㅇㅇ짓이라고 말못해서 삐진거야 빨갱아      1\n",
       "3                                           세탁이라고 봐도 된다      0\n",
       "4                                    애새끼가 초딩도 아니고 ㅋㅋㅋㅋ       1\n",
       "...                                                 ...    ...\n",
       "5820         좌우 헬파이어 3개씩 6개 장착에 아파치보다 약하지만 20mm 기관포 장착임      0\n",
       "5821  세금 내놓으라고 데모질 중 ㅋㅋ간첩, 도둑놈 새끼들이 대통령 해처먹으니까  나도 같...      1\n",
       "5822                                          너가 한 말 중에      0\n",
       "5823                                            제갈대중 ㅇㅂ      0\n",
       "5824                           우리나라교회는 악마들이모여 주뎅이 처벌리고       1\n",
       "\n",
       "[5825 rows x 2 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 456번째 라인에서 | 하나 지워야 함, 맨 윗줄에 'document|label' 추가\n",
    "benchmark_dataset = pd.read_csv('dataset.txt', sep='|')\n",
    "benchmark_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def benchmark_model(classifier, dataset):\n",
    "    documents = dataset['document'].to_list()\n",
    "    true_labels = dataset['label'].to_list()\n",
    "    inference = []\n",
    "\n",
    "    for doc in tqdm(documents):\n",
    "        output = classifier(doc)[0]\n",
    "        if output['label'] == 'ok_sen' or output['label'] == 'LABEL_0':\n",
    "            inference.append(0)\n",
    "        else:\n",
    "            inference.append(1)\n",
    "\n",
    "    acc = accuracy_score(true_labels, inference)\n",
    "    prec = precision_score(true_labels, inference)\n",
    "    rec = recall_score(true_labels, inference)\n",
    "    f1 = f1_score(true_labels, inference)\n",
    "\n",
    "    return [acc, prec, rec, f1], inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: :: benchmarking the comparison model :: ::\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5825/5825 [01:56<00:00, 50.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.81, precision=0.69, recall=0.87, f1=0.77\n",
      ":: :: benchmarking the klue_BERT model :: ::\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5825/5825 [22:10<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.83, precision=0.76, recall=0.75, f1=0.75\n",
      ":: :: benchmarking the kcElectra model :: ::\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5825/5825 [02:17<00:00, 42.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.68, precision=0.54, recall=0.66, f1=0.59\n",
      ":: :: benchmarking the kcBERT model :: ::\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5825/5825 [03:03<00:00, 31.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.76, precision=0.61, recall=0.85, f1=0.71\n",
      ":: :: benchmarking the klue_roBERTa model :: ::\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 1777/5825 [07:04<18:43,  3.60it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (602 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 5825/5825 [23:10<00:00,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.79, precision=0.67, recall=0.77, f1=0.72\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = {\n",
    "    \"comparison\" : comparison_classifier,\n",
    "    \"klue_BERT\" : klue_bert_classifier, \n",
    "    \"kcElectra\" : kcelectra_classifier, \n",
    "    \"kcBERT\" : kcbert_classifier, \n",
    "    \"klue_roBERTa\" : klue_roberta_classifier\n",
    "}\n",
    "inferences = []\n",
    "true_labels = benchmark_dataset['label'].to_list()\n",
    "\n",
    "for name, model in classifiers.items():\n",
    "    print(f':: :: benchmarking the {name} model :: ::')\n",
    "    scores, infer = benchmark_model(model, benchmark_dataset)\n",
    "    print(f'accuracy={scores[0]:.2f}, precision={scores[1]:.2f}, recall={scores[2]:.2f}, f1={scores[3]:.2f}')\n",
    "    inferences.append(infer)\n",
    "print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the benchmarking result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['label'] = true_labels\n",
    "for i, name in enumerate(classifiers.keys()):\n",
    "\tdf[name] = inferences[i]\n",
    "\n",
    "df.to_csv('inference.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with Youtube Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>이새끼는 근본이 안되어있어범죄자 새끼</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>개극혐이다 진짜</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>토할 것 같다..</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>승리 비판 전혀 상관없이 , 저 댓글들만 보여주는게 과연 sbs수준을 올릴까 내릴까?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>승리는 사람 아니다. 같이 우리나라 사회에 있어서는 안된다. 해외로 추방시켜야 한다...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>이새키보소</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>쓰레기는 변하지 않아~</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>멍ㄸㄹㅇ~옥살이하면 범죄자의 모든것이 없어지나?대대손손 기록에 남지않을까? 꼬리표처럼!!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>잘가라~멀리 안나간다 ㅡㅡ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>요목조목 다 따져봐도 특출나게 잘난것도 없는 난쟁이놈이 전생에 나라라도 구했는지 ㅋ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              document  label\n",
       "0                                 이새끼는 근본이 안되어있어범죄자 새끼      1\n",
       "1                                             개극혐이다 진짜      1\n",
       "2                                            토할 것 같다..      0\n",
       "3      승리 비판 전혀 상관없이 , 저 댓글들만 보여주는게 과연 sbs수준을 올릴까 내릴까?      0\n",
       "4    승리는 사람 아니다. 같이 우리나라 사회에 있어서는 안된다. 해외로 추방시켜야 한다...      0\n",
       "..                                                 ...    ...\n",
       "195                                              이새키보소      1\n",
       "196                                       쓰레기는 변하지 않아~      1\n",
       "197  멍ㄸㄹㅇ~옥살이하면 범죄자의 모든것이 없어지나?대대손손 기록에 남지않을까? 꼬리표처럼!!      1\n",
       "198                                     잘가라~멀리 안나간다 ㅡㅡ      0\n",
       "199  요목조목 다 따져봐도 특출나게 잘난것도 없는 난쟁이놈이 전생에 나라라도 구했는지 ㅋ...      1\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "youtube_comments = pd.read_csv('Youtube_Comments.csv', sep=',')\n",
    "youtube_comments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: :: benchmarking the comparison model :: ::\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:09<00:00, 20.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.77, precision=0.52, recall=0.90, f1=0.66\n",
      ":: :: benchmarking the klue_BERT model :: ::\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:47<00:00,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.89, precision=0.75, recall=0.80, f1=0.78\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = {\n",
    "    \"comparison\" : comparison_classifier,\n",
    "    \"klue_BERT\" : klue_bert_classifier, \n",
    "}\n",
    "inferences = []\n",
    "true_labels = youtube_comments['label'].to_list()\n",
    "\n",
    "for name, model in classifiers.items():\n",
    "    print(f':: :: benchmarking the {name} model :: ::')\n",
    "    scores, infer = benchmark_model(model, youtube_comments)\n",
    "    print(f'accuracy={scores[0]:.2f}, precision={scores[1]:.2f}, recall={scores[2]:.2f}, f1={scores[3]:.2f}')\n",
    "    inferences.append(infer)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['label'] = true_labels\n",
    "for i, name in enumerate(classifiers.keys()):\n",
    "\tdf[name] = inferences[i]\n",
    "\n",
    "df.to_csv('inference_youtube.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
